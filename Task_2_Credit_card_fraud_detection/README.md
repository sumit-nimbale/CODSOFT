ðŸš¨ Credit Card Fraud Detection using Machine Learning

End-to-end ML project to detect fraudulent credit card transactions on highly imbalanced data, with threshold optimization to maximize fraud recall.

ðŸ“Œ Project Overview

Credit card fraud detection is a real-world imbalanced classification problem, where fraudulent transactions account for <1% of all data.
Traditional accuracy-based evaluation fails in such scenarios.

This project builds industry-ready ML pipelines to:

Handle extreme class imbalance

Compare Logistic Regression vs Random Forest

Evaluate using Precision, Recall, F1, ROC-AUC, PR-AUC

Tune decision thresholds to maximize fraud detection (Recall)

Follow production-style modular code structure

ðŸŽ¯ Objective

Detect fraudulent credit card transactions while maximizing recall, ensuring fewer fraudulent transactions go undetected.

ðŸ§  Key ML Concepts Applied

Imbalanced classification handling

Class-weighted learning

Feature engineering from timestamps

High-cardinality categorical feature reduction

Pipeline-based preprocessing

Threshold tuning beyond default 0.5

ROC-AUC & Precision-Recall analysis

ðŸ“‚ Project Structure
credit-card-fraud-detection/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing.py      # Data loading, cleaning, splitting
â”‚   â”œâ”€â”€ feature_engineering.py     # Time & age feature creation
â”‚   â”œâ”€â”€ train_logistic_regression.py
â”‚   â”œâ”€â”€ train_random_forest.py
â”‚   â”œâ”€â”€ threshold_tuning.py        # Decision threshold optimization
â”‚   â”œâ”€â”€ evaluation.py              # Metrics & reports
â”‚   â””â”€â”€ utils.py                   # Common utilities & plots
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ EDA.ipynb                  # Exploratory analysis
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ fraud_train.csv
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ðŸ“Š Dataset

Source: Kaggle Credit Card Fraud Dataset

Target Variable: is_fraud

Class Distribution:

Legitimate: ~99.8%

Fraudulent: ~0.2%

âš™ï¸ Feature Engineering

Transaction hour

Transaction day

Transaction month

Customer age (derived from DOB)

High-cardinality category reduction

Scaled numerical features

One-Hot encoded categorical features

ðŸ¤– Models Implemented
1ï¸âƒ£ Logistic Regression

Class-weighted (class_weight='balanced')

Strong baseline for imbalanced data

Interpretable decision boundary

2ï¸âƒ£ Random Forest Classifier

Ensemble learning

Handles non-linear patterns

Robust to feature interactions

ðŸ“ˆ Evaluation Metrics

Accuracy is not reliable for imbalanced data.
This project focuses on:

Precision

Recall (Primary Metric)

F1 Score

ROC-AUC

PR-AUC

Confusion Matrix

ðŸŽ¯ Threshold Optimization (Core Highlight)

Instead of using the default threshold 0.5, multiple thresholds were evaluated:

Threshold range: 0.05 â†’ 0.9

Selected threshold that maximizes Recall

Compared performance before & after optimization

ðŸ“Œ This reflects real industry fraud systems, where missing fraud is costlier than false alarms.

ðŸ† Final Results Summary
Model	Threshold	Precision	Recall	F1	ROC-AUC
Logistic Regression (Default)	0.50	âœ“	âœ“	âœ“	âœ“
Logistic Regression (Optimized)	Tuned	â†‘	â†‘â†‘	â†‘	âœ“
Random Forest (Default)	0.50	âœ“	âœ“	âœ“	âœ“
Random Forest (Optimized)	Tuned	â†‘	â†‘â†‘	â†‘	âœ“

âž¡ Optimized models significantly improved fraud recall

ðŸ“Œ Final Recommendation

Model selected based on maximum Recall after threshold tuning, making it suitable for real-world fraud detection systems where minimizing false negatives is critical.

ðŸš€ How to Run
pip install -r requirements.txt
python main.py


(or run individual scripts from src/)

ðŸ§© Skills Demonstrated

Machine Learning

Imbalanced Data Handling

Feature Engineering

Model Evaluation

Threshold Optimization

Scikit-Learn Pipelines

Production-style ML code organization

ðŸ“£ Why This Project Matters

âœ… Industry-aligned
âœ… Interview-ready
âœ… Recruiter-friendly
âœ… Real-world ML logic
âœ… Beyond â€œaccuracyâ€ mindset
