{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "2aca9004-059e-4e75-8a9b-20f71fc42b6e",
      "cell_type": "code",
      "source": "#Import Required Libraries\n\nimport re\nimport string\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "id": "fe2144c1-bb59-4720-bd1a-81116a925c42",
      "cell_type": "code",
      "source": "#2.Loading Labeled Dataset\nprint(\"\\n==========================================\")\nprint(\"STEP 1:LOADING DATASET\")\nprint(\"==========================================\")\n\ndf = pd.read_csv(\"train_data.csv\",\n                 sep = \":::\",\n                 engine = \"python\",\n                 names = [\"id\", \"title\", \"genre\", \"text\"]\n                )\n\nprint(\"Dataset Loaded Successfully.\")\nprint(\"Columns Available:\", list(df.columns))\nprint(f\"Total records found:{len(df)}\\n\")",
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n==========================================\nSTEP 1:LOADING DATASET\n==========================================\nDataset Loaded Successfully.\nColumns Available: ['id', 'title', 'genre', 'text']\nTotal records found:54214\n\n"
        }
      ],
      "execution_count": 4
    },
    {
      "id": "07df36cf-adc6-4608-8717-91f92bebee46",
      "cell_type": "code",
      "source": "#3.Data Cleaning\nprint(\"\\n==========================================\")\nprint(\"STEP 2:Data Cleaning (Basic)\")\nprint(\"==========================================\\n\")\n\ndf = df[[\"text\", \"genre\"]]\ndf.dropna(subset=[\"text\", \"genre\"], inplace=True)\n\ndf[\"text\"] = df[\"text\"].str.strip()\ndf[\"genre\"] = df[\"genre\"].str.strip()\n\nprint(\"2A.TEXT AND COLUMNS SUCCESSFULLY CLEANED.\")\nprint(\"SAMPLE DATA AFTER BASIC CLEANING:-\")\nprint(df.head(5))\nprint(\"------------------------------------------\\n\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n==========================================\nSTEP 2:Data Cleaning (Basic)\n==========================================\n\n2A.TEXT AND COLUMNS SUCCESSFULLY CLEANED.\nSAMPLE DATA AFTER BASIC CLEANING:-\n                                                text     genre\n0  Listening in to a conversation between his doc...     drama\n1  A brother and sister with a past incestuous re...  thriller\n2  As the bus empties the students for their fiel...     adult\n3  To help their unemployed father make ends meet...     drama\n4  The film's title refers not only to the un-rec...     drama\n------------------------------------------\n\n"
        }
      ],
      "execution_count": 5
    },
    {
      "id": "f8b0f1e6-6d69-4ae5-880e-ca04f4d4d823",
      "cell_type": "code",
      "source": "#4.Text preprocessing function\ndef clean_sentence(sentence):\n    sentence = sentence.lower()\n    sentence = re.sub(r\"\\d+\", \"\", sentence)\n    sentence = sentence.translate(\n        str.maketrans(\"\", \"\", string.punctuation)\n    )\n    sentence = \" \".join(sentence.split())\n    return sentence\n\ndf[\"clean_text\"] = df[\"text\"].apply(clean_sentence)\nprint(\"2B.TEXT PROCESSING SUCCESSFULLY COMPLETED.\")\nprint(\"SAMPLE TEXT BEFORE AND AFTER PREPROCESSING:-\")\nsample_preview = df[[\"text\",\"clean_text\"]].head(5)\nprint(sample_preview)\nprint(\"------------------------------------------\\n\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "2B.TEXT PROCESSING SUCCESSFULLY COMPLETED.\nSAMPLE TEXT BEFORE AND AFTER PREPROCESSING:-\n                                                text  \\\n0  Listening in to a conversation between his doc...   \n1  A brother and sister with a past incestuous re...   \n2  As the bus empties the students for their fiel...   \n3  To help their unemployed father make ends meet...   \n4  The film's title refers not only to the un-rec...   \n\n                                          clean_text  \n0  listening in to a conversation between his doc...  \n1  a brother and sister with a past incestuous re...  \n2  as the bus empties the students for their fiel...  \n3  to help their unemployed father make ends meet...  \n4  the films title refers not only to the unrecov...  \n------------------------------------------\n\n"
        }
      ],
      "execution_count": 6
    },
    {
      "id": "608c642e-5173-44fe-8ea9-c7224b391af2",
      "cell_type": "code",
      "source": "#5.Feature-label Split\n\nX = df[\"clean_text\"]  # Input features (text)\ny = df[\"genre\"]       # Target labels (genre)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X,\n    y,\n    test_size=0.2,\n    random_state=42,\n    shuffle = True\n    )\n\nprint(\"\\n==========================================\")\nprint(\" STEP 3: DATA SPLITTING \")\nprint(\"==========================================\\n\")\n\nprint(f\"Data used to TRAIN (teach) the model : {len(X_train)} samples\")\nprint(f\"Data used to TEST  (check) the model : {len(X_test)} samples\\n\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n==========================================\n STEP 3: DATA SPLITTING \n==========================================\n\nData used to TRAIN (teach) the model : 43371 samples\nData used to TEST  (check) the model : 10843 samples\n\n"
        }
      ],
      "execution_count": 7
    },
    {
      "id": "670226a2-e62a-4008-bed4-7f08bb3bf9c2",
      "cell_type": "code",
      "source": "#6.Converting data from text to numerical format\nprint(\"\\n==========================================\")\nprint(\" STEP 4: TF-IDF VECTORIZATION \")\nprint(\"==========================================\")\n# Show example BEFORE conversion\nprint(\"-\" * 70)\nprint(\"TEXT BEFORE CONVERSION (HUMAN-READABLE):-\")\nprint(\"-\" * 70)\nprint(X_train.iloc[2], \"\\n\")\n\n# TF-IDF setup\nvectorizer = TfidfVectorizer(\n    stop_words=\"english\",\n    max_features=5000\n)\n\nX_train_vec = vectorizer.fit_transform(X_train)\nX_test_vec  = vectorizer.transform(X_test)\n\n# Show example AFTER conversion\nprint(\"-\" * 70)\nprint(\"TEXT AFTER CONVERSION (MACHINE READABLE NUMBERS):-\")\nprint(\"-\" * 70)\nprint(X_train_vec[2])",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n==========================================\n STEP 4: TF-IDF VECTORIZATION \n==========================================\n----------------------------------------------------------------------\nTEXT BEFORE CONVERSION (HUMAN-READABLE):-\n----------------------------------------------------------------------\nthe onehour special examines this socially ethnically religiously and economically diverse state that just like in could determine the outcome of the presidential election wilmore is intent on exploring how this unique state that produced two revered american institutions nascar and hooters will choose the next leader of the free world \n\n----------------------------------------------------------------------\nTEXT AFTER CONVERSION (MACHINE READABLE NUMBERS):-\n----------------------------------------------------------------------\n<Compressed Sparse Row sparse matrix of dtype 'float64'\n\twith 22 stored elements and shape (1, 5000)>\n  Coords\tValues\n  (0, 3129)\t0.25344944408414305\n  (0, 4194)\t0.162163112922227\n  (0, 1580)\t0.20131220727851937\n  (0, 4147)\t0.25941959407053256\n  (0, 1309)\t0.21940945319461352\n  (0, 4249)\t0.3362852060887856\n  (0, 2496)\t0.12408767886192275\n  (0, 2658)\t0.12936186090216395\n  (0, 1235)\t0.23965934621172305\n  (0, 3171)\t0.2550547379292665\n  (0, 3428)\t0.24868539128200742\n  (0, 1446)\t0.23335449814502562\n  (0, 2340)\t0.2421334586903523\n  (0, 1622)\t0.2121337799029445\n  (0, 4707)\t0.16303132207778587\n  (0, 3463)\t0.18946967329026576\n  (0, 161)\t0.14455410711659658\n  (0, 2331)\t0.25267336046786243\n  (0, 738)\t0.2067254660469273\n  (0, 2601)\t0.18457086564642647\n  (0, 1843)\t0.17648024122176112\n  (0, 4954)\t0.10343344950402615\n"
        }
      ],
      "execution_count": 8
    },
    {
      "id": "24bcf767-c7be-46e4-a55c-fba1a53927da",
      "cell_type": "code",
      "source": "\n#7.Training Model\n\n# ===============================\n# STEP 5: MODEL TRAINING\n# ===============================\n\nprint(\"\\n\" + \"-\" * 70)\nprint(\"STEP 5: MODEL TRAINING (NAIVE BAYES CLASSIFIER)\")\nprint(\"-\" * 70 + \"\\n\")\n\nmodel = MultinomialNB()\nmodel.fit(X_train_vec, y_train)\n\nprint(\"Status : Model training completed\")\nprint(\"Input  : TF-IDF numeric vectors\")\nprint(\"Output : Learned word–genre patterns\\n\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n----------------------------------------------------------------------\nSTEP 5: MODEL TRAINING (NAIVE BAYES CLASSIFIER)\n----------------------------------------------------------------------\n\nStatus : Model training completed\nInput  : TF-IDF numeric vectors\nOutput : Learned word–genre patterns\n\n"
        }
      ],
      "execution_count": 9
    },
    {
      "id": "36993f66-f826-4f12-a353-524b0a938649",
      "cell_type": "code",
      "source": "#8.Model Evaluation\n# Accuracy:\n# Measures overall correctness of the model.\n# (How many predictions were correct out of total predictions)\n\n# F1 Score:\n# Balances precision and recall.\n# Useful when classes are imbalanced.\n\n# Confusion Matrix:\n# Shows correct vs incorrect predictions for each class.\n# Helps analyze where the model gets confused.\nprint(\"==========================================\")\nprint(\" STEP 6: MODEL EVALUATION \")\nprint(\"==========================================\")\ny_pred = model.predict(X_test_vec)\n\naccuracy = accuracy_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred, average='weighted')\ncm = confusion_matrix(y_test, y_pred)\n\nprint(f\"Accuracy Score : {accuracy:.4f}\")\nprint(f\"F1 Score       : {f1:.4f}\")\nprint(\"Confusion Matrix:\")\nprint(cm)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "==========================================\n STEP 6: MODEL EVALUATION \n==========================================\nAccuracy Score : 0.5211\nF1 Score       : 0.4415\nConfusion Matrix:\n[[  20    0    0    0    0   18    0   55  154    0    0    0    0    8\n     0    0    0    0    0    0    0    2    3    0    2    0    1]\n [   0    6    7    0    0   37    0    9   49    0    0    0    0    0\n     0    0    0    0    0    0    0    3    0    0    1    0    0]\n [   3    0   10    0    0   10    0   38   66    0    0    0    0    7\n     0    0    0    0    0    0    1    2    0    0    0    0    2]\n [   0    0    0    0    0   18    0   38   45    0    0    0    0    0\n     0    0    0    0    0    0    0    3    0    0    0    0    0]\n [   0    0    0    0    0    2    0   39   20    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0]\n [   2    0    1    0    0  630    0  156  641    0    0    0    0    6\n     1    0    0    0    1    0    0    5    0    0    0    0    0]\n [   1    0    0    0    0    9    0   10   83    0    0    0    0    2\n     0    0    0    0    0    0    0    0    0    0    1    0    1]\n [   3    0    0    0    0   45    0 2327  263    0    0    0    0    3\n     0    0    0    0    1    0    0   16    0    0    1    0    0]\n [   3    0    0    0    0  145    0  301 2231    0    0    0    0    3\n     0    0    0    0    0    0    0   12    0    0    2    0    0]\n [   0    0    1    0    0   32    0   54   60    1    0    0    0    1\n     0    0    0    0    0    0    0    1    0    0    0    0    0]\n [   0    0    1    0    0    4    0   18   48    0    0    0    0    2\n     0    0    0    0    0    0    0    1    0    0    0    0    0]\n [   0    0    0    0    0   15    0   18    1    0    0    6    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0]\n [   0    0    0    0    0    0    0   32   13    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0]\n [   0    0    0    0    0   32    0   44  197    0    0    0    0  151\n     0    0    0    0    0    0    1    5    0    0    1    0    0]\n [   0    0    0    0    0   10    0  107    5    0    0    0    0    0\n    19    0    0    0    0    0    0    3    0    0    0    0    0]\n [   0    0    0    0    0   10    0   16   22    0    0    0    0    0\n     2    0    0    0    0    0    0    0    0    0    0    0    0]\n [   0    0    0    0    0    5    0    7   40    0    0    0    0    2\n     0    0    0    0    0    0    0    0    0    0    2    0    0]\n [   0    0    0    0    0    1    0   31    2    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0]\n [   0    0    0    0    0   50    0  116   18    0    0    0    0    0\n     0    0    0    0    4    0    0    4    0    0    0    0    0]\n [   0    0    0    0    0   16    0    8  127    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0]\n [   1    0    0    0    0   12    0   64   49    0    0    0    0    8\n     0    0    0    0    0    0    3    5    0    0    1    0    0]\n [   0    0    0    0    0   93    0  398  441    0    0    0    0    3\n     1    0    0    0    0    0    0  109    0    0    0    0    0]\n [   0    0    0    0    0    8    0   72    3    0    0    0    0    0\n     0    0    0    0    0    0    0    1    9    0    0    0    0]\n [   0    0    0    0    0    9    0   68    2    0    0    0    0    0\n     1    0    0    0    0    0    0    1    0    0    0    0    0]\n [   2    0    0    0    0   23    0   21  242    0    0    0    0   15\n     0    0    0    0    0    0    0    1    0    0    5    0    0]\n [   1    0    0    0    0    1    0   10    8    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0]\n [   0    0    0    0    0    9    0    5   67    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0  119]]\n"
        }
      ],
      "execution_count": 10
    },
    {
      "id": "efb8b29c-5029-46fb-b383-d57b3150decf",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}